\section{AI测试概述}

\subsection{智能软件和传统软件的区别}
\begin{itemize}
    \item 任务目标难以精确表达
    \item 非确定性开放环境运行
    \item 应用于复杂软硬件场景
    \item 输出的结果具有一定的随机性，AI测试的输出的结果与训练集的输入数据是非常相关的；而传统软件测试往往是有一个先验条件的，确定的输入能得到一个确定的输出
    \item 传统软件是由程序代码控制决策逻辑，而智能软件决策逻辑决由深度学习模型结构、训练后得到权重节点共同组成
\end{itemize}


\subsection{AI测试的难点}
\begin{itemize}
    \item 数据获取：对模型的训练和验证都需要大量的数据，如何获取到数据是一个最基本的问题。
    \item 数据质量：一般来说，数据质量越高，训练出的模型预测效果越好，如何评价和保障数据质量，是模型测试的另一个难点。
    \item 特征质量：特征直接影响到了模型的预测效果。特征维数过多，模型可能会过拟合；特征过少，模型可能会欠拟合。
    \item 结果验证：由于模型训练是黑盒形式，无法确认输入对应输出的逻辑是否准确。
    \item 线上服务效果验证：模型的测试不仅仅存在于上线前，随着时间的变化，模型的预测效果可能会出现偏差。如何实时跟踪这些变化，保证服务正常，也是需要关注的重点。
    \item 也存在不充分测试以及数据分布不均匀等问题
\end{itemize}

\subsection{图像扩增}
\begin{itemize}
    \item 基于图像处理的数据扩增
    \begin{itemize}
        \item 基于几何变换的扩增方法
        \begin{itemize}
            \item 旋转、缩放、平移、翻转、裁剪
        \end{itemize}
        \item 颜色空间变换：可以消除光照、亮度及色彩差异
        \begin{itemize}
            \item 亮度调整、对比度饱和度调整、颜色空间变换、色彩调整
        \end{itemize}
        \item 添加噪声和滤波
        \begin{itemize}
            \item 注入高斯噪声、椒盐噪声等；滤波：模糊、锐化等
        \end{itemize}
        \item 图像混合
        \item 随机擦除
    \end{itemize}
    \item 基于深度学习的数据扩增
    \begin{itemize}
        \item 基于GAN的数据增强：使用GAN生成模型来生成更多的数据，可用作解决类别不平衡问题的过采样技术
        \item 神经风格转换：通过神经网络风格迁移来生成不同风格的数据，防止模型过拟合
        \item AutoAugment
    \end{itemize}
\end{itemize}

\subsection{文本扩增}
\begin{itemize}
    \item 加噪（同义词替换、随机插入、随机替换、随机删除）以及回译
    \begin{itemize}
        \item 加噪：在原数据的基础 上通过替换词、删除词等方式创造和原数据相类
        似的新数据。
        \item 回译：将原有数据翻译为其他语言再翻译回原语言，由于语言逻辑顺序等的不同，回译的方法也往往能够得到和原数据差别较大的新数据。
    \end{itemize}
    \item 受限变分自编码器（CVAE），他是通过在回译的中间过程增加一些噪声，但增加过程很可能导致标签的变化，因此使用CVAE来同时考虑标签和文本来丰富中间过程的语言，最后可以翻译成原来的语言
    \item 文本生成、对抗生成
    \item 条件生成：使用模型判断可以替换的位置，然后再生成可以替换的词语
\end{itemize}

\subsection{公平性}
机器学习训练在涉及到性别、种族等与人相关的敏感属性时，常常会由于统计性偏差、算法本身甚至是人为偏见而引入歧视性行为。由此，为消除差别影响，改进机器学习公平性，主要途径包括提高训练数据集质量、改进算法降低对敏感属性的依赖以及定义指标量化和衡量歧视程度。\footnote{\url{https://blog.csdn.net/aizhushou/article/details/108724150}}

\subsection{后门攻击}
深度学习中的后门攻击通过后门模型学习攻击者选择的子任务和（良性）主任务的方式向DL模型植入后门：\footnote{\url{https://zhuanlan.zhihu.com/p/541578519}}
\begin{itemize}
    \item 一方面，对于不包含触发器的输入input，后门模型表现得与干净模型一样正常，因此仅通过检查测试样本的测试准确性来区分后门模型和干净模型是不可能的；
    \item 另一方面，一旦秘密触发器Trigger（只有攻击者知道）出现在输入中，后门模型就会被错误引导去执行攻击者的子任务，比如分类任务中将输入分类到攻击者指定的目标类别。
\end{itemize}
